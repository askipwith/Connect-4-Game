{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_strategy() with:\n",
    "- n depth recursion\n",
    "- alpa-beta pruned search\n",
    "\n",
    "Typical losses / 1000:\n",
    "- depth 0: 5.0% in 6 seconds\n",
    "- depth 1: 12.2%, 11.1%, 11.1% in 40 seconds\n",
    "- depth 2: 2.5% in 2 mins\n",
    "- depth 4: 0% in 13.5 mins / 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT 4 - V5 - IMPROVED ALGORITH, RECURSIVE WITH PUNING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# CONSTANTS\n",
    "\n",
    "# Game control\n",
    "DEPTH = 4\n",
    "DEBUG_OUTPUT = False\n",
    "# Game definition\n",
    "ROWS = 6\n",
    "COLUMNS = 7\n",
    "CONNECT_N = 4\n",
    "# Player definition - values ascribed later\n",
    "AI_PLAYER = None\n",
    "HUMAN_PLAYER = None\n",
    "# Board and player colours\n",
    "COLOUR_EMPTY = \"\\u2022 \"\n",
    "COLOUR_RED = \"\\U0001F534\"\n",
    "COLOUR_YELLOW = \"\\U0001F7E1\"\n",
    "COLOUR_BLACK = \"\\u26AB\" # black just fills the space for testing\n",
    "COLOUR_COUNTER=[COLOUR_EMPTY, COLOUR_RED, COLOUR_YELLOW, COLOUR_BLACK]\n",
    "COLOUR_TEXT = [\"Blank\", \"Red\", \"Yellow\", \"Black\"]\n",
    "# Test boards - columns containing rows from 0 upwards\n",
    "# AI playing red, put counter in column 2 and then lost, human counter in column 5\n",
    "TEST_BOARD_1 = np.array([[2,0,0,0,0,0],\n",
    "                         [1,2,0,0,0,0],\n",
    "                         [2,1,2,0,0,0],\n",
    "                         [2,1,0,0,0,0],\n",
    "                         [1,1,1,2,1,0],\n",
    "                         [2,2,2,0,0,0],\n",
    "                         [1,0,0,0,0,0]])\n",
    "# AI playing red, can't win as there are two winning moves for human\n",
    "TEST_BOARD_2 = np.array([[2,2,1,0,0,0],\n",
    "                         [1,2,2,2,0,0],\n",
    "                         [2,1,2,2,2,1],\n",
    "                         [2,1,2,1,0,0],\n",
    "                         [1,1,1,2,1,0],\n",
    "                         [2,2,2,1,1,0],\n",
    "                         [1,1,2,1,2,1]])\n",
    "# AI playing red, needs to spot forking move for human in col 0\n",
    "TEST_BOARD_3 = np.array([[2,0,0,0,0,0],\n",
    "                         [1,2,2,0,0,0],\n",
    "                         [2,1,2,2,2,1],\n",
    "                         [2,1,2,1,0,0],\n",
    "                         [1,1,1,2,1,0],\n",
    "                         [2,2,2,1,1,0],\n",
    "                         [1,1,2,1,2,0]])\n",
    "# AI playing red, cannot put counter in column 0\n",
    "TEST_BOARD_4 = np.array([[2,0,0,0,0,0],\n",
    "                         [1,2,2,2,1,2],\n",
    "                         [2,1,2,2,2,1],\n",
    "                         [2,1,2,1,1,2],\n",
    "                         [1,1,1,2,1,0],\n",
    "                         [2,2,2,1,1,0],\n",
    "                         [1,1,2,1,2,1]])\n",
    "\n",
    "# TEST_START is a tuple of the test board, starting player, and their colour\n",
    "TEST_START = None\n",
    "TEST_START = ('TEST_BOARD_1', 'AI_PLAYER', 1)\n",
    "\n",
    "def my_strategy(board, player_num):\n",
    "    # To interface into tester\n",
    "    # converts list of lists [[int]*6]*7 into np array\n",
    "    global AI_PLAYER, HUMAN_PLAYER, DEPTH\n",
    "    AI_PLAYER = player_num\n",
    "    HUMAN_PLAYER = AI_PLAYER ^ 3\n",
    "    return get_ai_move(np.array(board))\n",
    "\n",
    "def print_debug(str):\n",
    "    # Print debug output if enabled\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(str)\n",
    "\n",
    "def flip_coin():\n",
    "    # Returns True 50% of the time\n",
    "    return np.random.randint(2) == 1\n",
    "    \n",
    "def get_valid_moves(board):\n",
    "    # Returns a list of valid moves for the current board state\n",
    "    valid_moves = []\n",
    "    for col in range(COLUMNS):\n",
    "        if board[col,ROWS-1] == 0:\n",
    "            valid_moves.append(col)\n",
    "    return valid_moves\n",
    "\n",
    "def check_winner(board, player):\n",
    "    # Check horizontal, vertical, and diagonal lines for a win\n",
    "    for col in range(COLUMNS):\n",
    "        for row in range(ROWS):\n",
    "            # If cell is empty, no need to check this cell or cells above\n",
    "            if board[col, row] == 0:\n",
    "                break\n",
    "            # If cell is not the player, skip but keep checking cells above\n",
    "            if board[col, row] != player:\n",
    "                continue\n",
    "            # If room above... check vertical\n",
    "            if (row + CONNECT_N <= ROWS):\n",
    "                if all (board[col, row + i] == player for i in range(1, CONNECT_N)):\n",
    "                    return True\n",
    "            # If room to the right...\n",
    "            if (col + CONNECT_N <= COLUMNS):  # if room to the right\n",
    "                # ...check horizontal-right\n",
    "                if all (board[col + i, row] == player for i in range(1, CONNECT_N)):\n",
    "                    return True\n",
    "                # ...check diagonal up-right if room above\n",
    "                if (row + CONNECT_N <= ROWS):\n",
    "                    if all (board[col + i, row + i] == player for i in range(1, CONNECT_N)):\n",
    "                        return True\n",
    "                # ...check diagonal down-right if room below\n",
    "                if (row - CONNECT_N >= -1):\n",
    "                    if all (board[col + i, row - i] == player for i in range(1, CONNECT_N)):\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def check_draw(board):\n",
    "    return all (board[column, ROWS-1] !=0 for column in range(COLUMNS))\n",
    "\n",
    "def is_terminal_node(board):\n",
    "    # Check for Terminal Node (Win, Draw, or Continue)\n",
    "    return check_winner(board, AI_PLAYER) or check_winner(board, HUMAN_PLAYER) or check_draw(board)\n",
    "\n",
    "def evaluate_board(board, col, row):\n",
    "\n",
    "    def eval_get_counts(board, player_num, col, row, col_step, row_step):\n",
    "    # Returns the number of adjacent, separate, and blank cells in a line\n",
    "\n",
    "        def is_in_range(x, max):\n",
    "            return x >= 0 and x < max\n",
    "\n",
    "        count_same_adj = 0\n",
    "        count_same_sep = 0\n",
    "        count_blank = 0\n",
    "\n",
    "        # evaluate in both directions along the line dir -1 and 1\n",
    "        for eval_dir in range(-1,2,2):\n",
    "            check_adjacent = True\n",
    "            # explore up to CONNECT_N-1 spaces either side\n",
    "            for i in range(1, CONNECT_N):\n",
    "                check_column = col + col_step * eval_dir * i\n",
    "                check_row = row + row_step * eval_dir * i\n",
    "                # stop if off the board\n",
    "                if not (is_in_range(check_column,COLUMNS) and is_in_range(check_row,ROWS)):\n",
    "                    break\n",
    "                # stop if cell is opponent's\n",
    "                if board[check_column,check_row] == player_num ^ 3:\n",
    "                    break\n",
    "                # if the cell is a blank, count it but set adjacent to false\n",
    "                if board[check_column,check_row] == 0:\n",
    "                    count_blank += 1\n",
    "                    check_adjacent = False\n",
    "                # if the cell is the same colour, count adjacent or separate\n",
    "                if board[check_column,check_row] == player_num:\n",
    "                    if check_adjacent:\n",
    "                        count_same_adj += 1\n",
    "                    else:\n",
    "                        count_same_sep += 1\n",
    "        return count_same_adj, count_same_sep, count_blank\n",
    "\n",
    "    def eval_line(board, col, row, col_step, row_step):\n",
    "    # Returns a line score based on the number of adjacent, separate, and blank cells\n",
    "    # Score is from the perspective of last player i.e. player_num in [col,row]\n",
    "\n",
    "        # evaluation weightings\n",
    "        EVAL_SAME_ADJ = 2 # exponential\n",
    "        EVAL_SAME_SEP = 1 # linear\n",
    "        EVAL_BLANK = 1 # linear\n",
    "\n",
    "        eval_line_score = 0\n",
    "        player_num = board[col,row]\n",
    "\n",
    "        # Calculate offensive score\n",
    "        count_same_adj, count_same_sep, count_blank = eval_get_counts(board, player_num, col, row, col_step, row_step)\n",
    "        \n",
    "        # Only score a line if there is enough space to win\n",
    "        # NB function might return eval_line_score=0 (better than losing move)\n",
    "        if (count_same_adj + count_same_sep + count_blank) >= CONNECT_N - 1:\n",
    "            if count_same_adj > 0:\n",
    "                eval_line_score += EVAL_SAME_ADJ ** count_same_adj\n",
    "            eval_line_score += count_same_sep * EVAL_SAME_SEP\n",
    "            eval_line_score += count_blank * EVAL_BLANK\n",
    "\n",
    "        # Add a defensive score\n",
    "        count_same_adj, count_same_sep, count_blank = eval_get_counts(board, player_num ^ 3, col, row, col_step, row_step)\n",
    "        \n",
    "        # Only score a line if there is enough space for opponent to win\n",
    "        if (count_same_adj + count_same_sep + count_blank) >= CONNECT_N - 1:\n",
    "            if count_same_adj > 0:\n",
    "                eval_line_score += EVAL_SAME_ADJ ** count_same_adj\n",
    "            eval_line_score += count_same_sep * EVAL_SAME_SEP\n",
    "            eval_line_score += count_blank * EVAL_BLANK\n",
    "\n",
    "        return eval_line_score\n",
    "\n",
    "    def eval_move(board, col, row):\n",
    "    # Returns a score for a move based on the evaluation of each line\n",
    "\n",
    "        eval_move_score = 0\n",
    "        eval_steps = np.array([[1, 0], [1, 1], [0, 1], [1, -1]])\n",
    "        # Evaluate each line in turn\n",
    "        for i in range(4):\n",
    "            eval_move_score += eval_line(board, col, row, eval_steps[i, 0], eval_steps[i, 1])\n",
    "        return eval_move_score\n",
    "\n",
    "    # Check for a win, loss, or draw, otherwise return a heuristic evaluation\n",
    "    if check_winner(board, AI_PLAYER):\n",
    "        return np.inf  # AI wins\n",
    "    elif check_winner(board, HUMAN_PLAYER):\n",
    "        return -np.inf  # Human wins\n",
    "    elif check_draw(board):\n",
    "        return 0  # Draw\n",
    "    else:\n",
    "        # Heuristic evaluation for intermediate states (foccsing on the move that led to this board state)\n",
    "        return eval_move(board, col, row)\n",
    "\n",
    "def minimax(board, col, row, depth, maximizing_player, alpha=-np.inf, beta=np.inf):\n",
    "    \"\"\"\n",
    "    Perform the minimax algorithm with alpha-beta pruning to determine the best move for a player in a two-player game.\n",
    "    Args:\n",
    "        board (np.ndarray): The current state of the game board.\n",
    "        col (int): The column index of the last move made.\n",
    "        row (int): The row index of the last move made.\n",
    "        depth (int): The maximum depth to search in the game tree.\n",
    "        maximizing_player (bool): True if the current player is the maximizing player (AI), False if the current player is the minimizing player (Human).\n",
    "        alpha (float): The best value that the maximizer currently can guarantee at that level or above.\n",
    "        beta (float): The best value that the minimizer currently can guarantee at that level or above.\n",
    "    Returns:\n",
    "        int: The best score for the maximizing player at the top level of the game tree.\n",
    "    Summary:\n",
    "        - This function uses a recursive approach to explore all possible moves up to a given depth.\n",
    "        - This is a generic gaming function that can be used for any two-player game\n",
    "        - Each level represents a player's turn, alternating between maximizing and minimizing players\n",
    "    Notes:\n",
    "        - The maximizing player aims to maximize the score, while the minimizing player aims to minimize it.\n",
    "        - The function terminates when the depth is 0 or a terminal node (win/loss/draw) is reached.\n",
    "        - The function evaluates the board state using the `evaluate_board` function and determines valid moves using the `get_valid_moves` function.\n",
    "        - The `make_move` function is used to simulate moves on the board.\n",
    "    More on the Return value:\n",
    "        - The return value is the best score that the maximizing player can achieve from the current board state, considering all possible moves up to the specified depth.\n",
    "        - This score is determined by recursively evaluating the game tree and propagating the best scores back up the recursion chain.\n",
    "        - The top-level return value represents the best score for the maximizing player (AI) at the root node of the game tree.\n",
    "    More on the algorithm used:\n",
    "        - Alpha-beta pruning optimizes the search by cutting off branches that do not need to be explored.\n",
    "    Why ODD Depth values:\n",
    "        - The algorithm tends to win more games with odd depth values because it allows the AI (maximizing player) to make the final move in the search tree.\n",
    "        - With an odd depth, the AI evaluates the board state after the human (minimizing player) has made their move, giving the AI the opportunity to respond optimally.\n",
    "        - This ensures that the AI's strategy is based on the most recent move by the opponent, leading to better decision-making and higher chances of winning.\n",
    "    \"\"\"\n",
    "\n",
    "    if depth == 0 or is_terminal_node(board):\n",
    "        return evaluate_board(board, col, row), depth\n",
    "    \n",
    "    valid_moves = get_valid_moves(board)\n",
    "    if maximizing_player:\n",
    "        best_value = -np.inf\n",
    "        best_depth = -1\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            row = make_move(new_board, col, AI_PLAYER)  # AI is the maximizing player\n",
    "            #  print_debug(f\"\\n<Testing AI move to [{col},{row}] - depth: {depth}...\")\n",
    "            #  print_debug(f\" - best_value: {best_value}, best_depth: {best_depth}\")\n",
    "            best_child_value, best_child_depth = minimax(new_board, col, row, depth-1, False, alpha, beta)\n",
    "            #  print_debug(f\" - best_child_value: {best_child_value}, best_child_depth: {best_child_depth}\")\n",
    "            if (best_child_value > best_value or \n",
    "                (best_child_value == best_value and best_child_depth > best_depth)):\n",
    "                best_value, best_depth = best_child_value, best_child_depth\n",
    "                #  print_debug(f\"SO SWITCHING... best_value: {best_value}, best_depth: {best_depth}\")\n",
    "            alpha = max(alpha, best_value)\n",
    "            \"\"\"\n",
    "            Alpha is the best score so far at this level\n",
    "            # If the current value is greater than or equal to beta, no need to explore further\n",
    "            # This is because the minimizing player will avoid this branch (beta cut-off)\n",
    "            # If alpha >= beta, the opponent will never allow this to happen because they will always choose the lower value\n",
    "            \"\"\"\n",
    "            # NB THIS WAS >= BUT SEEMED TO INTERFERE WITH THE DEPTH CHOICE\n",
    "\n",
    "            \"\"\"\n",
    "            if alpha > beta:  # Beta was the min (best opponent move) at the level above i.e. previous level\n",
    "                break  # Beta cut-off\n",
    "            \"\"\"\n",
    "\n",
    "        return best_value, best_depth\n",
    "    else:\n",
    "        best_value = np.inf\n",
    "        best_depth = -1\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            row = make_move(new_board, col, HUMAN_PLAYER)  # Human is the minimizing player\n",
    "            #  print_debug(f\"\\n>Testing HUMAN move to: [{col},{row}] - depth: {depth}...\")\n",
    "            #  print_debug(f\" - best_value: {best_value}, best_depth: {best_depth}\")\n",
    "            best_child_value, best_child_depth = minimax(new_board, col, row, depth-1, True, alpha, beta)\n",
    "            #  print_debug(f\" - best_child_value: {best_child_value}, best_child_depth: {best_child_depth}\")         \n",
    "            if (best_child_value < best_value or \n",
    "                (best_child_value == best_value and best_child_depth > best_depth)):\n",
    "                best_value, best_depth = best_child_value, best_child_depth\n",
    "                #  print_debug(f\"SO SWITCHING... best_value: {best_value}, best_depth: {best_depth}\")\n",
    "            beta = min(beta, best_value)\n",
    "\n",
    "            \"\"\"\n",
    "            if alpha > beta: # NEED TO ADD CASE FOR alpha==beta with depth test\n",
    "                break  # Alpha cut-off\n",
    "            \"\"\"\n",
    "\n",
    "        return best_value, best_depth\n",
    "\n",
    "def make_move(board, col, player):\n",
    "    # Updates the board col with the player's move amd return the row\n",
    "    row = next(r for r in range(ROWS) if board[col, r] == 0)\n",
    "    board[col, row] = player\n",
    "    return row\n",
    "\n",
    "def get_ai_move(board):\n",
    "    # Returns the best move for the AI player\n",
    "    valid_moves = get_valid_moves(board)\n",
    "    best_col_value = -np.inf\n",
    "    best_col_depth = np.inf\n",
    "    best_col = valid_moves[0]  # Default - just in case the only moves are losing\n",
    "    for col in valid_moves:\n",
    "        print_debug(f\"\\nTESTING COLUMN: {col}...\")\n",
    "        new_board = board.copy()\n",
    "        row = make_move(new_board, col, AI_PLAYER)\n",
    "        # This initiates the minimax recursion\n",
    "        this_col_value, this_col_depth = minimax(new_board, col, row, DEPTH, False)\n",
    "        # Choose the best move\n",
    "        print_debug(f\"Column: {col} - value: {this_col_value}, depth: {this_col_depth}...\")\n",
    "        # If this column's value is worse than the best so far then continue\n",
    "        if (this_col_value < best_col_value):\n",
    "            continue\n",
    "        # If this is the same value...\n",
    "        if (this_col_value == best_col_value):\n",
    "            # ...and the depth is the same then flip a coin\n",
    "            if this_col_depth == best_col_depth and flip_coin():\n",
    "                continue\n",
    "            # if both are unfavourable moves then choose the one with the greater depth\n",
    "            if this_col_value < 0  and this_col_depth > best_col_depth:\n",
    "                continue\n",
    "            # if both are favourable moves then choose the one with the lesser depth\n",
    "            if this_col_value > 0 and this_col_depth < best_col_depth:\n",
    "                continue\n",
    "        # other cases screened out, so switch to this column\n",
    "        best_col, best_col_value, best_col_depth = col, this_col_value, this_col_depth\n",
    "    return best_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing student strategy...\n",
      "Beginning game 2 of 200.\r"
     ]
    }
   ],
   "source": [
    "# When you're ready to run your strategy run the top cell, then this cell\n",
    "# You can do this as often as you like as you improve your strategy\n",
    "\n",
    "from assessment.assessor import assess\n",
    "assess(my_strategy, 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dbf766eb95023f9dddb799b5381b4ed6a9322e38632e8ac1570872c767b304b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
