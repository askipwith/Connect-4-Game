{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_strategy() with:\n",
    "- n depth recursion\n",
    "- alpa-beta pruned search\n",
    "\n",
    "Typical losses / 1000:\n",
    "- depth 0: 5.0% in 4 seconds\n",
    "- depth 1: 12.2%, 11.1%, 11.1% in 43 seconds\n",
    "- depth 2: 2.5% in 2.5 mins \n",
    "- depth 3: 3.4% in 10 mins\n",
    "- depth 4: 1.6% in 36 mins\n",
    "- depth 5: ?? in 140 mins\n",
    "- depth 6: ?? in 550 mins\n",
    "\n",
    "Pruning:\n",
    "- does not seem to have harmed accuracy\n",
    "- improves speed sigificantly at greater depths: x3 depth 3, x5 depth 4\n",
    "\n",
    "Odd depths: still worse than even depths (not surprising, same algorithm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT 4 - V4 - RECURSIVE WITH PUNING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# CONSTANTS\n",
    "\n",
    "# Game control\n",
    "DEPTH = 0\n",
    "DEBUG_OUTPUT = False\n",
    "# Game definition\n",
    "ROWS = 6\n",
    "COLUMNS = 7\n",
    "CONNECT_N = 4\n",
    "# Player definition - values ascribed later\n",
    "AI_PLAYER = None\n",
    "HUMAN_PLAYER = None\n",
    "# Board and player colours\n",
    "COLOUR_EMPTY = \"\\u2022 \"\n",
    "COLOUR_RED = \"\\U0001F534\"\n",
    "COLOUR_YELLOW = \"\\U0001F7E1\"\n",
    "COLOUR_BLACK = \"\\u26AB\" # black just fills the space for testing\n",
    "COLOUR_COUNTER=[COLOUR_EMPTY, COLOUR_RED, COLOUR_YELLOW, COLOUR_BLACK]\n",
    "COLOUR_TEXT = [\"Blank\", \"Red\", \"Yellow\", \"Black\"]\n",
    "\n",
    "def my_strategy(board, player_num):\n",
    "    # To interface into tester\n",
    "    # converts list of lists [[int]*6]*7 into np array\n",
    "    global AI_PLAYER, HUMAN_PLAYER\n",
    "    AI_PLAYER = player_num\n",
    "    HUMAN_PLAYER = AI_PLAYER ^ 3\n",
    "    return get_ai_move(np.array(board))\n",
    "\n",
    "def print_debug(str):\n",
    "    # Print debug output if enabled\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(str)\n",
    "\n",
    "def flip_coin():\n",
    "    # Returns True 50% of the time\n",
    "    return np.random.randint(2) == 1\n",
    "    \n",
    "def get_valid_moves(board):\n",
    "    # Returns a list of valid moves for the current board state\n",
    "    valid_moves = []\n",
    "    for col in range(COLUMNS):\n",
    "        if board[col,ROWS-1] == 0:\n",
    "            valid_moves.append(col)\n",
    "    return valid_moves\n",
    "\n",
    "def check_winner(board, player):\n",
    "    # Check horizontal, vertical, and diagonal lines for a win\n",
    "    for col in range(COLUMNS):\n",
    "        for row in range(ROWS):\n",
    "            # If cell is empty, no need to check this cell or cells above\n",
    "            if board[col, row] == 0:\n",
    "                break\n",
    "            # If cell is not the player, skip but keep checking cells above\n",
    "            if board[col, row] != player:\n",
    "                continue\n",
    "            # If room above... check vertical\n",
    "            if (row + CONNECT_N <= ROWS):\n",
    "                if all (board[col, row + i] == player for i in range(1, CONNECT_N)):\n",
    "                    return True\n",
    "            # If room to the right...\n",
    "            if (col + CONNECT_N <= COLUMNS):  # if room to the right\n",
    "                # ...check horizontal-right\n",
    "                if all (board[col + i, row] == player for i in range(1, CONNECT_N)):\n",
    "                    return True\n",
    "                # ...check diagonal up-right if room above\n",
    "                if (row + CONNECT_N <= ROWS):\n",
    "                    if all (board[col + i, row + i] == player for i in range(1, CONNECT_N)):\n",
    "                        return True\n",
    "                # ...check diagonal down-right if room below\n",
    "                if (row - CONNECT_N >= -1):\n",
    "                    if all (board[col + i, row - i] == player for i in range(1, CONNECT_N)):\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def check_draw(board):\n",
    "    return all (board[column, ROWS-1] !=0 for column in range(COLUMNS))\n",
    "\n",
    "def is_terminal_node(board):\n",
    "    # Check for Terminal Node (Win, Draw, or Continue)\n",
    "    return check_winner(board, AI_PLAYER) or check_winner(board, HUMAN_PLAYER) or check_draw(board)\n",
    "\n",
    "def evaluate_board(board, col, row):\n",
    "\n",
    "    def eval_get_counts(board, player_num, col, row, col_step, row_step):\n",
    "    # Returns the number of adjacent, separate, and blank cells in a line\n",
    "\n",
    "        def is_in_range(x, max):\n",
    "            return x >= 0 and x < max\n",
    "\n",
    "        count_same_adj = 0\n",
    "        count_same_sep = 0\n",
    "        count_blank = 0\n",
    "\n",
    "        # evaluate in both directions along the line dir -1 and 1\n",
    "        for eval_dir in range(-1,2,2):\n",
    "            check_column = col + col_step * eval_dir\n",
    "            check_row = row + row_step * eval_dir\n",
    "            check_adjacent = True\n",
    "            # explore up to CONNECT_N-1 spaces either side\n",
    "            for depth in range(CONNECT_N - 1):\n",
    "                # stop if off the board\n",
    "                if not (is_in_range(check_column,7) and is_in_range(check_row,6)):\n",
    "                    break\n",
    "                # stop if cell is opponent's\n",
    "                if board[check_column,check_row] == player_num ^ 3:\n",
    "                    break\n",
    "                # if the cell is a blank, count it but set adjacent to false\n",
    "                if board[check_column,check_row] == 0:\n",
    "                    count_blank += 1\n",
    "                    check_adjacent = False\n",
    "                # if the cell is the same colour, count adjacent or separate\n",
    "                if board[check_column,check_row] == player_num:\n",
    "                    if check_adjacent:\n",
    "                        count_same_adj += 1\n",
    "                    else:\n",
    "                        count_same_sep += 1\n",
    "                check_column += col_step * eval_dir\n",
    "                check_row += row_step * eval_dir\n",
    "        return count_same_adj, count_same_sep, count_blank\n",
    "\n",
    "    def eval_line(board, col, row, col_step, row_step):\n",
    "    # Returns a line score based on the number of adjacent, separate, and blank cells\n",
    "    # Score is from the perspective of last player i.e. player_num in [col,row]\n",
    "\n",
    "        # evaluation weightings\n",
    "        EVAL_SAME_ADJ = 2 # exponential\n",
    "        EVAL_SAME_SEP = 1 # linear\n",
    "        EVAL_BLANK = 1 # linear\n",
    "\n",
    "        eval_line_score = 0\n",
    "        player_num = board[col,row]\n",
    "\n",
    "        # Calculate offensive score\n",
    "        count_same_adj, count_same_sep, count_blank = eval_get_counts(board, player_num, col, row, col_step, row_step)\n",
    "        \n",
    "        # Only score a line if there is enough space to win\n",
    "        # NB function might return eval_line_score=0 (better than losing move)\n",
    "        if (count_same_adj + count_same_sep + count_blank) >= CONNECT_N - 1:\n",
    "            if count_same_adj > 0:\n",
    "                eval_line_score += EVAL_SAME_ADJ ** count_same_adj\n",
    "            eval_line_score += count_same_sep * EVAL_SAME_SEP\n",
    "            eval_line_score += count_blank * EVAL_BLANK\n",
    "            print_debug(f\"offense: count_same_adj: {count_same_adj}, count_same_sep: {count_same_sep}, count_blank: {count_blank}, eval score: {eval_line_score}\")\n",
    "\n",
    "        # Add a defensive score\n",
    "        count_same_adj, count_same_sep, count_blank = eval_get_counts(board, player_num ^ 3, col, row, col_step, row_step)\n",
    "        \n",
    "        # Only score a line if there is enough space for opponent to win\n",
    "        if (count_same_adj + count_same_sep + count_blank) >= CONNECT_N - 1:\n",
    "            if count_same_adj > 0:\n",
    "                eval_line_score += EVAL_SAME_ADJ ** count_same_adj\n",
    "            eval_line_score += count_same_sep * EVAL_SAME_SEP\n",
    "            eval_line_score += count_blank * EVAL_BLANK\n",
    "            print_debug(f\"defense: count_same_adj: {count_same_adj}, count_same_sep: {count_same_sep}, count_blank: {count_blank}, eval score: {eval_line_score}\")\n",
    "\n",
    "        return eval_line_score\n",
    "\n",
    "    def eval_move(board, col, row):\n",
    "    # Returns a score for a move based on the evaluation of each line\n",
    "\n",
    "        eval_move_score = 0\n",
    "        eval_steps = np.array([[1, 0], [1, 1], [0, 1], [1, -1]])\n",
    "        # Evaluate each line in turn\n",
    "        for i in range(4):\n",
    "            print_debug(f\"evaluating line {i}\")\n",
    "            eval_move_score += eval_line(board, col, row, eval_steps[i, 0], eval_steps[i, 1])\n",
    "        print_debug(f\"column {col} score: {eval_move_score}\")\n",
    "        return eval_move_score\n",
    "\n",
    "    # Check for a win, loss, or draw, otherwise return a heuristic evaluation\n",
    "    if check_winner(board, AI_PLAYER):\n",
    "        return np.inf  # AI wins\n",
    "    elif check_winner(board, HUMAN_PLAYER):\n",
    "        return -np.inf  # Human wins\n",
    "    elif check_draw(board):\n",
    "        return 0  # Draw\n",
    "    else:\n",
    "        # Heuristic evaluation for intermediate states (foccsing on the move that led to this board state)\n",
    "        return eval_move(board, col, row)\n",
    "\n",
    "def minimax(board, col, row, depth, maximizing_player, alpha=-np.inf, beta=np.inf):\n",
    "    \"\"\"\n",
    "    Perform the minimax algorithm with alpha-beta pruning to determine the best move for a player in a two-player game.\n",
    "    Args:\n",
    "        board (np.ndarray): The current state of the game board.\n",
    "        col (int): The column index of the last move made.\n",
    "        row (int): The row index of the last move made.\n",
    "        depth (int): The maximum depth to search in the game tree.\n",
    "        maximizing_player (bool): True if the current player is the maximizing player (AI), False if the current player is the minimizing player (Human).\n",
    "        alpha (float): The best value that the maximizer currently can guarantee at that level or above.\n",
    "        beta (float): The best value that the minimizer currently can guarantee at that level or above.\n",
    "    Returns:\n",
    "        int: The best score for the maximizing player at the top level of the game tree.\n",
    "    Summary:\n",
    "        - This function uses a recursive approach to explore all possible moves up to a given depth.\n",
    "        - This is a generic gaming function that can be used for any two-player game\n",
    "        - Each level represents a player's turn, alternating between maximizing and minimizing players\n",
    "    Notes:\n",
    "        - The maximizing player aims to maximize the score, while the minimizing player aims to minimize it.\n",
    "        - The function terminates when the depth is 0 or a terminal node (win/loss/draw) is reached.\n",
    "        - The function evaluates the board state using the `evaluate_board` function and determines valid moves using the `get_valid_moves` function.\n",
    "        - The `make_move` function is used to simulate moves on the board.\n",
    "    More on the Return value:\n",
    "        - The return value is the best score that the maximizing player can achieve from the current board state, considering all possible moves up to the specified depth.\n",
    "        - This score is determined by recursively evaluating the game tree and propagating the best scores back up the recursion chain.\n",
    "        - The top-level return value represents the best score for the maximizing player (AI) at the root node of the game tree.\n",
    "    More on the algorithm used:\n",
    "        - Alpha-beta pruning optimizes the search by cutting off branches that do not need to be explored.\n",
    "    Why ODD Depth values:\n",
    "        - The algorithm tends to win more games with odd depth values because it allows the AI (maximizing player) to make the final move in the search tree.\n",
    "        - With an odd depth, the AI evaluates the board state after the human (minimizing player) has made their move, giving the AI the opportunity to respond optimally.\n",
    "        - This ensures that the AI's strategy is based on the most recent move by the opponent, leading to better decision-making and higher chances of winning.\n",
    "    \"\"\"\n",
    "\n",
    "    if depth == 0 or is_terminal_node(board):\n",
    "        return evaluate_board(board, col, row)\n",
    "    \n",
    "    valid_moves = get_valid_moves(board)\n",
    "    if maximizing_player:\n",
    "        value = -np.inf\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            row = make_move(new_board, col, AI_PLAYER)  # AI is the maximizing player\n",
    "            value = max(value, minimax(new_board, col, row, depth-1, False, alpha, beta))\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                break  # Beta cut-off\n",
    "        if depth == DEPTH:\n",
    "            print_debug(f\"AI value (best case): {value}\")\n",
    "        return value\n",
    "    else:\n",
    "        value = np.inf\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            row = make_move(new_board, col, HUMAN_PLAYER)  # Human is the minimizing player\n",
    "            value = min(value, minimax(new_board, col, row, depth-1, True, alpha, beta))\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta:\n",
    "                break  # Alpha cut-off\n",
    "        if depth == DEPTH:\n",
    "            print_debug(f\"Human value (worst case): {value}\")\n",
    "        return value\n",
    "\n",
    "def make_move(board, col, player):\n",
    "    # Updates the board col with the player's move amd return the row\n",
    "    row = next(r for r in range(ROWS) if board[col, r] == 0)\n",
    "    board[col, row] = player\n",
    "    return row\n",
    "\n",
    "def get_ai_move(board):\n",
    "    # Returns the best move for the AI player\n",
    "    valid_moves = get_valid_moves(board)\n",
    "    best_score = -np.inf\n",
    "    best_col = valid_moves[0]  # Default - just in case the only moves are losing\n",
    "    for col in valid_moves:\n",
    "        new_board = board.copy()\n",
    "        row = make_move(new_board, col, AI_PLAYER)\n",
    "        # This initiates the minimax recursion\n",
    "        score = minimax(new_board, col, row, DEPTH, False)\n",
    "        # Choose the best move\n",
    "        if score > best_score or (score == best_score and flip_coin()):\n",
    "            best_score = score\n",
    "            best_col = col\n",
    "    return best_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing student strategy...\n",
      "                                                                                                    \n",
      "Results\n",
      "Wins: 879\n",
      "Draws: 0\n",
      "Losses: 121\n",
      "Forfeits: 0\n",
      "Mark: 75.94%\n"
     ]
    }
   ],
   "source": [
    "# When you're ready to run your strategy run the top cell, then this cell\n",
    "# You can do this as often as you like as you improve your strategy\n",
    "from assessment.assessor import assess\n",
    "\n",
    "assess(my_strategy, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dbf766eb95023f9dddb799b5381b4ed6a9322e38632e8ac1570872c767b304b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
